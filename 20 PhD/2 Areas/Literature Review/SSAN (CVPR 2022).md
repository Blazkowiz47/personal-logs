aliases: [ssan_fas]
tags: [paper, pad, deep-fas-survey, domain-generalization]
authors: Zhuo Wang, Zezheng Wang, Zitong Yu, Weihong Deng, Jiahong Li, Tingting Gao, Zhongyuan Wang
year: 2022
venue: CVPR
paper_url: https://arxiv.org/abs/2203.05340
code_url: https://github.com/wangzhuo2019/SSAN
status: "ðŸ“š To Read"
dateadded: 2025-11-26
dateread: 
priority: medium
# Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing

> [!abstract]
> With diverse presentation attacks emerging continually, generalizable face anti-spoofing (FAS) has drawn growing attention. Most existing methods implement domain generalization (DG) on the complete representations. However, different image statistics may have unique properties for the FAS tasks. In this work, we separate the complete representation into content and style ones. A novel Shuffled Style Assembly Network (SSAN) is proposed to extract and reassemble different content and style features for a stylized feature space. Then, to obtain a generalized representation, a contrastive learning strategy is developed to emphasize liveness-related style information while suppress the domain-specific one. Finally, the representations of the correct assemblies are used to distinguish between living and spoofing during the inferring. On the other hand, despite the decent performance, there still exists a gap between academia and industry, due to the difference in data quantity and distribution. Thus, a new large-scale benchmark for FAS is built up to further evaluate the performance of algorithms in reality. Both qualitative and quantitative results on existing and proposed benchmarks demonstrate the effectiveness of our methods.

## What does the paper present?
## What are my views on it?
