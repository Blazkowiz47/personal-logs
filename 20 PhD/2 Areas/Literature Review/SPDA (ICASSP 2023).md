---
aliases: [spda_fas]
tags: [paper, pad, deep-fas-survey, domain-generalization]
authors: Zhiyi Chen, Yao Lu, Xinzhe Deng, Jia Meng, Shengchuan Zhang, Liujuan Cao
year: 2023
venue: ICASSP
paper_url: https://ieeexplore.ieee.org/document/10095730
code_url: 
status: "ðŸ“š To Read"
dateadded: 2025-11-26
dateread: 
priority: medium
---
# Self-Paced Partial Domain-Aware Learning for Face Anti-Spoofing

> [!abstract]
> With the widespread deployment of face authentication systems, domain generalization (DG) based face anti-spoofing (FAS) security approaches have drawn growing attention. Existing generalization-based methods always attempt to extract domain-invariant task information from data and eliminate domain-dependent information from representation space. However, they neglect that domain-related information may also contain helpful features for the classification task. To address this issue, we propose a self-paced partial domain-aware framework (SPDA) to preserve domain-related features helpful for the discrimination of fake and real faces, thereby increasing generalization for unseen domains. Specifically, a training strategy based on contrastive learning is adopted to construct domain-adapted and domain-aware task-related representation spaces. Then, a partial domain-aware adaptation module (PDA) is proposed to preserve valuable domain-related information for the task features that the network considers useful for mixture-domain classification. In addition, the proposed self-paced method(SCM) continuously explores potential clusters with insufficient representation to enhance further the feature extractorâ€™s capability and the effectiveness of the PDA module. Extensive experiments demonstrate the effectiveness of our method compared to SOTA algorithms.

## What does the paper present?
What problem does this paper address?

*Describe the model/approach*

*What's new/different from prior work?*

*Key metrics and performance*

*What components were tested?*

*Anything useful for implementing this*

- [[]]

- [[]]

- [[]]

## What are my views on it?
*My thoughts on the paper*

*How does this relate to my PAD research?*

>

- Figure X:

$$
$$

*Discussions with advisor/colleagues about this paper*

- [ ]
- [ ]

---
**Reading Progress:**
- [ ] Abstract
- [ ] Introduction
- [ ] Related Work
- [ ] Methodology
- [ ] Experiments
- [ ] Conclusion
- [ ] Supplementary Material
