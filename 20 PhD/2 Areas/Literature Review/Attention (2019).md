aliases: [attention_fas]
tags: [paper, pad, deep-fas-survey, multimodal]
authors: 
year: 2019
venue: 
paper_url: https://openaccess.thecvf.com/content_CVPRW_2019/html/CFS/Wang_Multi-Modal_Face_Presentation_Attack_Detection_via_Spatial_and_Channel_Attentions_CVPRW_2019_paper.html
code_url: 
status: "ðŸ“š To Read"
dateadded: 2025-11-26
dateread: 
priority: medium
## What does the paper present?
Traditional PAD approaches lack generalization due to limited modalities and subjects. Simple concatenation of modalities is suboptimal as not all features are equally important.

1. **Multi-Modal Fusion:** Proposes an end-to-end approach fusing RGB, Depth, and IR.
2. **Spatial and Channel Attention:** Introduces attention modules to select discriminative features spatially and across channels.
3. **Performance:** Achieves promising results on the CASIA-SURF dataset.

## What are my views on it?
