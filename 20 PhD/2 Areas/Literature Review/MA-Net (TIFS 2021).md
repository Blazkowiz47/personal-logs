---
aliases: [ma_net_fas]
tags: [paper, pad, deep-fas-survey, multimodal, cross-modality-translation]
authors: Ajian Liu, Zichang Tan, Jun Wan, Yanyan Liang, Zhen Lei, Guodong Guo, Stan Z. Li
year: 2021
venue: TIFS
paper_url: https://ieeexplore.ieee.org/document/9374963
code_url: 
status: "ðŸ“š To Read"
dateadded: 2025-11-26
dateread:
priority: medium
---
## What does the paper present?
- **Backbone:** CycleGAN, ResNet18
- **Loss:** Binary CE loss, GAN loss
- **Input:** RGB, NIR
- **Fusion:** Feature-level

What problem does this paper address?

*Describe the model/approach*

*What's new/different from prior work?*

*Key metrics and performance*

*What components were tested?*

*Anything useful for implementing this*

- [[]]

- [[]]

- [[]]

## What are my views on it?
*My thoughts on the paper*

*How does this relate to my PAD research?*

>

- Figure X:

$$
$$

*Discussions with advisor/colleagues about this paper*

- [ ]
- [ ]

---
**Reading Progress:**
- [ ] Abstract
- [ ] Introduction
- [ ] Related Work
- [ ] Methodology
- [ ] Experiments
- [ ] Conclusion
- [ ] Supplementary Material
